# SynchroRaMa
### Lip-Synchronized and Emotion-Aware Talking Face Generation via Multi-Modal Emotion Embedding

Phyo Thet Yee<sup>1</sup>, Dimitrios Kollias<sup>2</sup>, Sudeepta Mishra<sup>1</sup>, Abhinav Dhall<sup>3</sup> <br><br>
<sup>1</sup>Indian Institute of Technology Ropar, <sup>2</sup>Queen Mary University of London, <sup>3</sup>Monash University <br>

**Accepted at WACV 2026 Conference**

<p>
  <a href="http://arxiv.org/abs/2509.19965">
    <img src="https://img.shields.io/badge/arXiv-Paper-red?style=flat" alt="arXiv">
  </a>
  <a href="https://novicemm.github.io/synchrorama">
    <img src="https://img.shields.io/badge/Project-Page-blue?style=flat" alt="Project Page">
  </a>
</p>

<br>
<p align="center">
  <img src="/content/synchrorama_teaser.png" alt="Teaser Image" width="600"/>
</p>

## Code is coming soon!!!

## Citation
```bibtex
@misc{yee2025synchroramalipsynchronizedemotionaware,
  title={SynchroRaMa : Lip-Synchronized and Emotion-Aware Talking Face Generation via Multi-Modal Emotion Embedding}, 
  author={Yee, Phyo Thet and Kollias, Dimitrios and Mishra, Sudeepta and Dhall, Abhinav},
  year={2025},
  eprint={2509.19965},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2509.19965}, 
}


